{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c012843c-bed6-4a6b-9eeb-8552f13aa3e2",
   "metadata": {},
   "source": [
    "Pipeline 1: Thu thập Dữ liệu và Tiền xử lý ban đầu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec105bd2-eb1b-412d-9ed9-688adda18008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # Thư viện sử dụng để làm việc với hệ thống tệp và thư mục\n",
    "import fitz  # Thư viện (PyMuPDF) sử dụng để đọc và xử lý các tệp PDF\n",
    "import pandas as pd  # Thư viện sử dụng để quản lý và phân tích dữ liệu dưới dạng bảng (DataFrame)\n",
    "from sklearn.preprocessing import LabelEncoder  # Thư viện sử dụng để mã hóa các nhãn thành giá trị số\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  # Thư viện sử dụng để xử lý văn bản trong TensorFlow Keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences  # Thư viện sử dụng để xử lý chuỗi trong TensorFlow Keras\n",
    "from sklearn.model_selection import train_test_split  # Thư viện sử dụng để chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "from sklearn.utils.class_weight import compute_class_weight  # Thư viện sử dụng để tính trọng số của các lớp để xử lý vấn đề không cân bằng dữ liệu\n",
    "\n",
    "# Hàm để trích xuất văn bản từ một file PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    document = fitz.open(pdf_path)  # Mở file PDF\n",
    "    return \" \".join([page.get_text() for page in document])  # Lấy văn bản từ mỗi trang và gộp lại thành chuỗi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "023fa18b-cbfa-4644-953d-119466d9db52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trích xuất văn bản từ tất cả các file PDF trong thư mục và lưu vào CSV\n",
    "pdf_folder = \"C:/Users/pngoc/Downloads/Smart-Talent-Resume-Ranker-kapil-development/Smart-Talent-Resume-Ranker-kapil-development/CV\"\n",
    "data = [{\"filename\": pdf_file, \"content\": extract_text_from_pdf(os.path.join(pdf_folder, pdf_file))} for pdf_file in os.listdir(pdf_folder)]\n",
    "pd.DataFrame(data).to_csv(\"cv_texts.csv\", index=False)  # Tạo DataFrame từ danh sách và lưu vào CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ddc7be2d-40a4-4f15-aa6c-9140c1f7f414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tải và chuẩn hóa dữ liệu từ các file CSV\n",
    "def load_and_standardize_csv(file_path, text_col, label_col=None, default_label=0):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['text'] = df[text_col]\n",
    "    df['label'] = df[label_col] if label_col else default_label\n",
    "    return df[['text', 'label']]\n",
    "\n",
    "category_df = load_and_standardize_csv(\"C:/Users/pngoc/Downloads/Smart-Talent-Resume-Ranker-kapil-development/Smart-Talent-Resume-Ranker-kapil-development/Datasets/cleaned_category_data.csv\", 'category')\n",
    "encoded_category_df = load_and_standardize_csv(\"C:/Users/pngoc/Downloads/Smart-Talent-Resume-Ranker-kapil-development/Smart-Talent-Resume-Ranker-kapil-development/Datasets/cleaned_encoded_category_data.csv\", 'category', 'encoded_category')\n",
    "jobs_classify_df = load_and_standardize_csv(\"C:/Users/pngoc/Downloads/Smart-Talent-Resume-Ranker-kapil-development/Smart-Talent-Resume-Ranker-kapil-development/Datasets/cleaned_jobs_classify_data.csv\", 'text', 'category')\n",
    "jobs_skills_df = load_and_standardize_csv(\"C:/Users/pngoc/Downloads/Smart-Talent-Resume-Ranker-kapil-development/Smart-Talent-Resume-Ranker-kapil-development/Datasets/cleaned_jobs_skills_data.csv\", 'skills', 'category')\n",
    "resume_skills_df = load_and_standardize_csv(\"C:/Users/pngoc/Downloads/Smart-Talent-Resume-Ranker-kapil-development/Smart-Talent-Resume-Ranker-kapil-development/Datasets/cleaned_resume_skills_data.csv\", 'Resume', 'Category')\n",
    "new_skills_df = load_and_standardize_csv(\"C:/Users/pngoc/Downloads/Smart-Talent-Resume-Ranker-kapil-development/Smart-Talent-Resume-Ranker-kapil-development/Datasets/cleaned_new_skills_data.csv\", 'skills')\n",
    "skill_set_df = load_and_standardize_csv(\"C:/Users/pngoc/Downloads/Smart-Talent-Resume-Ranker-kapil-development/Smart-Talent-Resume-Ranker-kapil-development/Datasets/cleaned_skill_set_data.csv\", 'skills')\n",
    "\n",
    "combined_df = pd.concat([category_df, encoded_category_df, jobs_classify_df, jobs_skills_df, resume_skills_df, new_skills_df, skill_set_df], ignore_index=True).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4edbe21-3bcf-4c2e-bb2b-f615947c0143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56039e50-94c6-41d7-b40a-8720e2912e59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05739467-2b05-4524-a8e6-d51f0acde4d7",
   "metadata": {},
   "source": [
    "Pipeline 2: Xây dụng và huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce03c6f1-7125-455f-a310-8ea2da4df2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 397ms/step - accuracy: 0.0270 - loss: 5.9424 - val_accuracy: 3.3602e-04 - val_loss: 5.1911 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 298ms/step - accuracy: 0.0739 - loss: 5.5406 - val_accuracy: 0.0013 - val_loss: 5.5817 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 370ms/step - accuracy: 0.0617 - loss: 5.5821 - val_accuracy: 0.0062 - val_loss: 5.3401 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m478s\u001b[0m 428ms/step - accuracy: 0.0467 - loss: 5.3975 - val_accuracy: 0.3346 - val_loss: 4.5135 - learning_rate: 2.0000e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m497s\u001b[0m 445ms/step - accuracy: 0.0330 - loss: 5.1186 - val_accuracy: 0.3317 - val_loss: 4.8087 - learning_rate: 2.0000e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m434s\u001b[0m 389ms/step - accuracy: 0.0359 - loss: 5.1136 - val_accuracy: 0.3470 - val_loss: 4.5689 - learning_rate: 2.0000e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 335ms/step - accuracy: 0.0318 - loss: 5.0734 - val_accuracy: 0.3543 - val_loss: 4.4009 - learning_rate: 1.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 316ms/step - accuracy: 0.0375 - loss: 4.9670 - val_accuracy: 0.3386 - val_loss: 4.5722 - learning_rate: 1.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 319ms/step - accuracy: 0.0331 - loss: 5.0560 - val_accuracy: 0.3478 - val_loss: 4.4830 - learning_rate: 1.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m1116/1116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 313ms/step - accuracy: 0.0425 - loss: 4.9158 - val_accuracy: 0.3403 - val_loss: 4.7539 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x224501b56d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Import các thư viện cần thiết\n",
    "from tensorflow.keras.models import Sequential  # Xây dựng các mô hình tuần tự (sequential models) của Keras\n",
    "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Dropout, BatchNormalization, Bidirectional  # Các lớp của Keras để xây dựng mô hình deep learning\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping  # Cung cấp các callback để điều chỉnh tốc độ học (learning rate) và dừng sớm (early stopping) khi huấn luyện mô hình, kiểu mô hình không hiệu quả thì nó sẽ dừng\n",
    "\n",
    "model = Sequential()  # Khởi tạo mô hình tuần tự\n",
    "model.add(Embedding(input_dim=5000, output_dim=128))  # Thêm lớp Embedding để chuyển đổi các từ thành vector số\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))  # Sử dụng Bi-LSTM (LSTM hai chiều) để mô hình học từ cả hai hướng của chuỗi\n",
    "model.add(BatchNormalization())  # Thêm lớp BatchNormalization để chuẩn hóa các đầu ra của lớp trước đó\n",
    "model.add(Dropout(0.5))  # Thêm lớp Dropout để ngăn chặn quá khớp (overfitting) bằng cách loại bỏ ngẫu nhiên một số đơn vị trong lớp\n",
    "model.add(GRU(64))  # Thêm lớp GRU (Gated Recurrent Unit) để học các mối quan hệ trong chuỗi\n",
    "model.add(BatchNormalization())  # Thêm lớp BatchNormalization để chuẩn hóa các đầu ra của lớp trước đó\n",
    "model.add(Dropout(0.5))  # Thêm lớp Dropout để tránh overfitting\n",
    "model.add(Dense(128, activation='relu'))  # Thêm lớp Dense (lớp dày) với hàm kích hoạt ReLU\n",
    "model.add(Dropout(0.5))  # Thêm lớp Dropout để tránh overfitting\n",
    "model.add(Dense(len(le.classes_), activation='softmax'))  # Thêm lớp Dense cuối cùng với hàm kích hoạt softmax để phân loại đầu ra\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0001)  # Callback để giảm tốc độ học khi độ lỗi không giảm\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)  # Callback để dừng sớm nếu độ lỗi không giảm sau một số lần huấn luyện\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # Biên dịch mô hình với hàm mất mát (loss function) và trình tối ưu hóa (optimizer)\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), callbacks=[reduce_lr, early_stopping], class_weight=class_weights_dict)  # Huấn luyện mô hình với dữ liệu huấn luyện và các callback đã thiết lập"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a8604e15-2988-4bcf-93a5-c709112119c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Matching Score: 84.32%\n"
     ]
    }
   ],
   "source": [
    "# Demo quy trình dự đoán điểm CV\n",
    "def predict_matching_score(cv_text):\n",
    "    cv_seq = tokenizer.texts_to_sequences([cv_text])  # Chuyển đổi văn bản CV thành chuỗi số\n",
    "    cv_pad = pad_sequences(cv_seq, maxlen=100)  # Thực hiện padding (thêm) chuỗi số đến độ dài cố định\n",
    "    score = model.predict(cv_pad)  # Dự đoán điểm số dựa trên mô hình đã huấn luyện\n",
    "    matching_percentage = score.max() * 10000  # Chuyển đổi điểm cao nhất thành tỷ lệ phần trăm\n",
    "    return matching_percentage\n",
    "\n",
    "# Ví dụ sử dụng\n",
    "new_cv_text = extract_text_from_pdf(r\"C:\\Users\\pngoc\\Downloads\\Smart-Talent-Resume-Ranker-kapil-development\\Smart-Talent-Resume-Ranker-kapil-development\\CV\\nikhilkumar9917103088 - Nikhil kumar.pdf\")  # Trích xuất văn bản từ file PDF CV mới\n",
    "matching_score = predict_matching_score(new_cv_text)  # Dự đoán điểm phù hợp của CV mới\n",
    "print(f\"Matching Score: {matching_score:.2f}%\")  # In ra điểm phù hợp của CV mới"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa1c120-1a8d-48a2-a6fe-881a1f4c0b97",
   "metadata": {},
   "source": [
    "Pipeline 3: Đánh giá mô hình dựa trên Precision và Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae405883-860e-47da-877e-44196b20f5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 84ms/step\n",
      "Precision: 0.5936313992584782\n",
      "Recall: 0.032195190947666194\n"
     ]
    }
   ],
   "source": [
    "# Import các thư viện cần thiết\n",
    "from sklearn.metrics import precision_score, recall_score  # Tính toán các chỉ số precision và recall\n",
    "\n",
    "y_pred = model.predict(X_test).argmax(axis=1)  # Dự đoán nhãn (label) từ mô hình và lấy chỉ số của giá trị lớn nhất\n",
    "precision = precision_score(y_test, y_pred, average='macro', zero_division=1)  # Tính toán chỉ số precision cho từng lớp (macro average)\n",
    "recall = recall_score(y_test, y_pred, average='macro', zero_division=1)  # Tính toán chỉ số recall cho từng lớp (macro average)\n",
    "\n",
    "print(f\"Precision: {precision}\")  # In ra chỉ số precision\n",
    "print(f\"Recall: {recall}\")  # In ra chỉ số recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cfa4df-5621-40f4-b571-505448737a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
